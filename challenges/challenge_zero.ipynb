{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2adzcfnbRZZY",
      "metadata": {
        "id": "2adzcfnbRZZY"
      },
      "source": [
        "# Challenge $0$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eccd6e67",
      "metadata": {
        "id": "eccd6e67"
      },
      "source": [
        "## 1. ***Data cleaning with Pandas***\n",
        "\n",
        "Use the library `pandas` to load and clean the required dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "39ae18d1",
      "metadata": {
        "id": "39ae18d1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6XPiwcNUPJAw",
      "metadata": {
        "id": "6XPiwcNUPJAw"
      },
      "source": [
        "Obtain the data file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AkGFWaHZOi-l",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkGFWaHZOi-l",
        "outputId": "d3f5701e-813f-4a20-b4f6-9a696a13db68"
      },
      "outputs": [],
      "source": [
        "FFILE = './50_Startups.csv'\n",
        "if os.path.isfile(FFILE):\n",
        "    print(\"File already exists\")\n",
        "    if os.access(FFILE, os.R_OK):\n",
        "        print (\"File is readable\")\n",
        "    else:\n",
        "        print (\"File is not readable, removing it and downloading again\")\n",
        "        !rm FFILE\n",
        "        !curl \"https://raw.github.com/alexdepremia/ML_IADA_UTs/main/challenge_0/50_Startups.csv\"\n",
        "else:\n",
        "    print(\"Either the file is missing or not readable, download it\")\n",
        "    !curl \"https://raw.github.com/alexdepremia/ML_IADA_UTs/main/challenge_0/50_Startups.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "984f3c35",
      "metadata": {
        "id": "984f3c35"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset using Pandas\n",
        "data = pd.read_csv('50_Startups.csv')\n",
        "\n",
        "# Extracting the features (independent variables) and labels (dependent variable)\n",
        "# Features (X) are taken from all columns except the last two\n",
        "features = data.iloc[:, :-2].values\n",
        "\n",
        "# Labels (y) are taken from the third column (index 3, considering the 0-based index in Python)\n",
        "labels = data.iloc[:, 3].values\n",
        "\n",
        "df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4ef5d4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4ef5d4c",
        "outputId": "cf3c7846-be10-4336-c752-ab72ab27446f"
      },
      "outputs": [],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c52b5bb",
      "metadata": {
        "id": "6c52b5bb"
      },
      "source": [
        "***Play with data***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bc66e09",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bc66e09",
        "outputId": "b6caed56-df56-4145-e1e3-74da105f824a",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f5107f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "9f5107f7",
        "outputId": "5bb6e213-9082-45a4-b49d-515803201e70"
      },
      "outputs": [],
      "source": [
        "df.replace(to_replace = 0.00, value = df.mean(axis=0, numeric_only=True), inplace=True)  # inject the mean of the column when value is 0\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c-RZI0p4Q7TW",
      "metadata": {
        "id": "c-RZI0p4Q7TW"
      },
      "source": [
        " **`df.replace()` function:**\n",
        "   - This function is used to replace specific values within a DataFrame (`df`) with another value.\n",
        "   - The parameters used are:\n",
        "     - `to_replace=0.00`: This specifies the value in the DataFrame that needs to be replaced, in this case, `0.00`.\n",
        "     - `value=df.mean(axis=0)`: This sets the replacement value for the matched condition. Here, `df.mean(axis=0)` calculates the mean for each column along the rows (axis=0) of the DataFrame `df`. The mean value for each column will replace the `0.00` values.\n",
        "     - `inplace=True`: This parameter ensures that the modification is done directly on the original DataFrame (`df`) without creating a new DataFrame. If `inplace` is set to `True`, the original DataFrame is modified."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bfef008",
      "metadata": {
        "id": "3bfef008"
      },
      "source": [
        "***Select two categories for binary classification***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "57f10ca0",
      "metadata": {
        "id": "57f10ca0"
      },
      "outputs": [],
      "source": [
        "df_sel=df[(df.State==\"California\") | (df.State==\"Florida\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "add6c146",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "add6c146",
        "outputId": "0f681332-4913-47f8-8640-f7db53b8b7e8"
      },
      "outputs": [],
      "source": [
        "df_sel.head() # column title and first rows of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32984bcc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32984bcc",
        "outputId": "5d110736-c5ca-4ee5-dd89-2fd922a4c08c"
      },
      "outputs": [],
      "source": [
        "df_sel.dtypes # type of each column"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0784375e",
      "metadata": {
        "id": "0784375e"
      },
      "source": [
        "***Encode categorical data***\n",
        "\n",
        "One-hot encoding of categorical feature _State_\n",
        "\n",
        "One-Hot Encoding is a technique used in machine learning to handle categorical variables by transforming them into a format that can be easily utilized by algorithms.\n",
        "\n",
        "Imagine having a categorical variable, such as colors: red, green, and blue. With One-Hot Encoding, each color becomes a new binary column. If an observation has a specific color, the column corresponding to that color will be set to 1, while the other columns will be set to 0.\n",
        "\n",
        "For example:\n",
        "- If you have categories \"red\", \"green\", \"blue\", and you want to encode them using One-Hot Encoding:\n",
        "  - \"red\" becomes [1, 0, 0]\n",
        "  - \"green\" becomes [0, 1, 0]\n",
        "  - \"blue\" becomes [0, 0, 1]\n",
        "\n",
        "This helps machine learning algorithms to understand and work with these categorical variables more effectively, as it doesn't impose an order or hierarchy among the categories but rather represents them in a form that the algorithm can interpret more efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "0a6b154f",
      "metadata": {
        "id": "0a6b154f"
      },
      "outputs": [],
      "source": [
        "df_one = pd.get_dummies(df_sel[\"State\"], dtype=int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f282229",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3f282229",
        "outputId": "af6ae211-c29f-4e55-e9f3-02fded7df40c",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df_one.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74e5d9d7",
      "metadata": {
        "id": "74e5d9d7"
      },
      "outputs": [],
      "source": [
        "# construct the final dataset that you will use for learning and prediction\n",
        "df_fin = pd.concat((df_one, df_sel), axis=1)\n",
        "df_fin = df_fin.drop([\"Florida\"], axis=1)\n",
        "df_fin = df_fin.drop([\"State\"], axis=1)\n",
        "# California is class 1, Florida is class 0\n",
        "df_fin = df_fin.rename(columns={\"California\": \"State\"})\n",
        "df_fin.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QlHeJ5ePRi6U",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QlHeJ5ePRi6U",
        "outputId": "9f8088d0-741a-4a67-c74e-90537fef9752"
      },
      "outputs": [],
      "source": [
        "# Constructing the final dataset for learning and prediction\n",
        "\n",
        "# Concatenating two DataFrames 'df_one' and 'df_sel' along columns (axis=1)\n",
        "df_fin = pd.concat((df_one, df_sel), axis=1)\n",
        "\n",
        "# Dropping the column \"Florida\" from the dataset as it was not selected for the final model\n",
        "df_fin = df_fin.drop([\"Florida\"], axis=1)\n",
        "\n",
        "# Dropping the column \"State\" (assumed to be the original 'State' column) as it is not required in its original form\n",
        "df_fin = df_fin.drop([\"State\"], axis=1)\n",
        "\n",
        "# Renaming the column \"California\" to \"State\" as part of preparing the dataset for classification (1 for California, 0 for Florida)\n",
        "df_fin = df_fin.rename(columns={\"California\": \"State\"})\n",
        "\n",
        "# Displaying the initial rows of the modified final dataset\n",
        "df_fin.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffced933",
      "metadata": {
        "id": "ffced933"
      },
      "source": [
        "***Normalize***\n",
        "\n",
        "Divide by the absolute value of the maximum so that features are in \\[0, 1\\]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "eb704286",
      "metadata": {
        "id": "eb704286"
      },
      "outputs": [],
      "source": [
        "def absolute_maximum_scale(series):\n",
        "    return series / series.abs().max()\n",
        "\n",
        "for col in df_fin.columns:\n",
        "    df_fin[col] = absolute_maximum_scale(df_fin[col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "5gURVDdmR52t",
      "metadata": {
        "id": "5gURVDdmR52t"
      },
      "outputs": [],
      "source": [
        "def absolute_maximum_scale(series):\n",
        "    \"\"\"\n",
        "    Scale each column in the DataFrame 'df_fin' by dividing the values by the absolute maximum value of that column.\n",
        "\n",
        "    Args:\n",
        "    series: A pandas Series or DataFrame column to be scaled.\n",
        "\n",
        "    Returns:\n",
        "    A scaled version of the input series with values ranging from -1 to 1 based on the maximum absolute value in the column.\n",
        "    \"\"\"\n",
        "    return series / series.abs().max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "vGQyMhhuR_5L",
      "metadata": {
        "id": "vGQyMhhuR_5L"
      },
      "outputs": [],
      "source": [
        "# Apply the 'absolute_maximum_scale' function to each column in the DataFrame 'df_fin'\n",
        "for col in df_fin.columns:\n",
        "    df_fin[col] = absolute_maximum_scale(df_fin[col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "421fc34c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "421fc34c",
        "outputId": "4bdb8956-5059-46cd-d5ca-1ff06e2f3f18"
      },
      "outputs": [],
      "source": [
        "df_fin.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XouS4L7nSTzL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XouS4L7nSTzL",
        "outputId": "3a51a8a4-e09e-437d-c684-165c8b0bb3cf"
      },
      "outputs": [],
      "source": [
        "df_fin.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "563bfeca",
      "metadata": {
        "id": "563bfeca"
      },
      "source": [
        "***Classification***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e3406c4",
      "metadata": {
        "id": "5e3406c4"
      },
      "source": [
        "Prepare the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "bc04f61d",
      "metadata": {
        "id": "bc04f61d"
      },
      "outputs": [],
      "source": [
        "y = df_fin[\"State\"] # ground truth labels\n",
        "X = df_fin.drop([\"State\"], axis=1) # datapoints features\n",
        "# extract actual values from series\n",
        "y = y.values\n",
        "X = X.values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b65051f",
      "metadata": {
        "id": "7b65051f"
      },
      "source": [
        "Train test split\n",
        "\n",
        "$75\\%$ of the data are in the training set, the remaining $25\\%$ constitutes the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "f11e105c",
      "metadata": {
        "id": "f11e105c"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "# X represents the features (independent variables), and y represents the target (dependent variable).\n",
        "\n",
        "# Using train_test_split function to create the training and testing sets\n",
        "# X_train and y_train: Training features and labels\n",
        "# X_test and y_test: Testing features and labels\n",
        "\n",
        "# The 'test_size=0.25' parameter sets the proportion of the dataset to include in the test split. Here, 25% of the data is allocated to the test set.\n",
        "# The 'random_state=0' parameter sets the random seed for reproducibility of the split.\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ee09c7e",
      "metadata": {
        "id": "5ee09c7e"
      },
      "source": [
        "Train the Logistic Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "1d4b2d20",
      "metadata": {
        "id": "1d4b2d20"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "S71_9HAkSg7w",
      "metadata": {
        "id": "S71_9HAkSg7w"
      },
      "outputs": [],
      "source": [
        "# Creating a Logistic Regression model with specific parameters\n",
        "# - 'random_state=0' ensures reproducibility by setting the random seed.\n",
        "# - 'solver='lbfgs'' selects the optimization algorithm for the logistic regression.\n",
        "\n",
        "LR = LogisticRegression(random_state=0, solver='lbfgs').fit(X_train, y_train)\n",
        "\n",
        "# Predicting the target variable (y) using the Logistic Regression model on the test set (X_test).\n",
        "predictions = LR.predict(X_test)\n",
        "\n",
        "# Calculating and rounding the accuracy score of the Logistic Regression model on the test set.\n",
        "# The score is calculated by comparing the predicted values to the actual values (y_test).\n",
        "accuracy = round(LR.score(X_test, y_test), 4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f9b7d00",
      "metadata": {
        "id": "6f9b7d00"
      },
      "source": [
        "***Plot results***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fae229d6",
      "metadata": {
        "id": "fae229d6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0a2a78f4",
      "metadata": {
        "id": "0a2a78f4"
      },
      "source": [
        "***Add regularization***\n",
        "\n",
        "Implement from scratch the regularized logistic regression model (with all the regularization techniques seen during the course)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68a3e1fa",
      "metadata": {
        "id": "68a3e1fa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7a05776d",
      "metadata": {
        "id": "7a05776d"
      },
      "source": [
        "***Model assessment***\n",
        "\n",
        "Given true and predicted values, compute the most common classification metrics to assess the quality of your predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3a864f9",
      "metadata": {
        "id": "b3a864f9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_true = y_test\n",
        "y_pred = LR.predict(X_test)\n",
        "\n",
        "target_names = ['California', 'Florida']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "q8gI_LEMJsB-",
      "metadata": {
        "id": "q8gI_LEMJsB-"
      },
      "source": [
        "Repeat the previous task for regularized logistic regression and compare the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AWSiwxDUJrZz",
      "metadata": {
        "id": "AWSiwxDUJrZz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d208a7b9",
      "metadata": {
        "id": "d208a7b9"
      },
      "source": [
        "***ROC curve***\n",
        "\n",
        "Implement a function for producing the Receiver Operating Characteristic (ROC) curve.\n",
        "\n",
        "Given true and predicted values, plot the ROC curve using your implemented function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "944188f5",
      "metadata": {
        "id": "944188f5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
